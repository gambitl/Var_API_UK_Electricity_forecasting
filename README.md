# ğŸ“ˆ Projet de prÃ©diction du prix du cours du gaz naturel au Royaume-Uni

Ce projet se focalise sur la mise en production d'un modÃ¨le de sÃ©ries temporelles multivariÃ© visant Ã  prÃ©dire le prix du cours du gaz naturel au Royaume-Uni. Le modÃ¨le est rÃ©alisÃ© en utilisant la librairie `statsmodels`.

## Architecture

Le projet est mis en production sur Google Cloud Platform (GCP) en utilisant les services suivants :

1. ğŸ“‚ **Google Cloud Storage** : les donnÃ©es d'entraÃ®nement sont stockÃ©es dans un bucket Google Cloud Storage dÃ©diÃ©.
2. ğŸ³ **API et container Docker** : le modÃ¨le est rendu accessible au public via une API hÃ©bergÃ©e dans un container Docker. Il expose une page HTML.
3. ğŸ”¨ **Google Cloud Build** : intÃ©gration continue et dÃ©ploiement du container Docker grÃ¢ce Ã  Google Cloud Build.
4. â˜ï¸ **Google Cloud Run** : dÃ©ploiement du container Docker sur Google Cloud Run, permettant d'exÃ©cuter l'API.
5. ğŸ›ï¸ **Google Cloud Composer** : le fichier Python du DAG Airflow, situÃ© dans le dossier "dag_airflow" du projet, est utilisÃ© pour rÃ©-entraÃ®ner le modÃ¨le toutes les heures. Le DAG s'exÃ©cute sur la brique Google Cloud Composer.
6. ğŸ“Š **MLFlow** : toutes les mÃ©triques d'entraÃ®nement et les artefacts, tels que le modÃ¨le, sont sauvegardÃ©s et historisÃ©s en utilisant la librairie Python MLFlow. Les donnÃ©es de MLFlow sont stockÃ©es dans un autre bucket Google Cloud Storage dÃ©diÃ©.
7. ğŸ—„ï¸ **PostgreSQL** : les donnÃ©es de MLFlow sont Ã©galement sauvegardÃ©es dans une base de donnÃ©es PostgreSQL.
8. ğŸ’» **Google Cloud Compute Engine** : la brique MLFlow s'exÃ©cute sur une machine virtuelle crÃ©Ã©e Ã  l'aide de Google Cloud Compute Engine.

## Configuration et dÃ©ploiement

1. ğŸš€ CrÃ©ez un projet sur Google Cloud Platform et configurez les services nÃ©cessaires, tels que Google Cloud Build, Google Cloud Run et Google Cloud Composer.
2. ğŸ“¦ CrÃ©ez les buckets Google Cloud Storage nÃ©cessaires, l'un pour stocker les donnÃ©es d'entraÃ®nement et l'autre pour sauvegarder les sorties de MLFlow. Mettez Ã  jour les chemins correspondants dans le code.
3. âš™ï¸ Configurez les paramÃ¨tres spÃ©cifiques du projet, tels que les identifiants d'accÃ¨s Ã  GCP, les chemins vers les donnÃ©es d'entraÃ®nement, etc.
4. ğŸ–¥ï¸ CrÃ©ez une machine virtuelle sur Google Cloud Compute Engine et configurez l'environnement MLFlow.
5. ğŸ—ƒï¸ CrÃ©ez une base de donnÃ©es PostgreSQL pour stocker les donnÃ©es de MLFlow et configurez les paramÃ¨tres de connexion dans le code.
6. ğŸ”„ Mettez en place le DAG Airflow en important dans l'interface de Composer le fichier Python du DAG situÃ© dans le dossier "dag_airflow" du projet.
7. ğŸš¢ Construisez le container Docker grÃ¢ce Ã  la brique Google Cloud Build (vous pouvez configurez une CI automatique en liant votre repo GIT comme nous l'avons fait) et dÃ©ployez-le sur Google Cloud Run.

## Documentation

La documentation dÃ©taillÃ©e sur la construction des diffÃ©rents services cloud et les dÃ©marches Ã  suivre se trouve dans le dossier `docs` du projet. ğŸ“š
